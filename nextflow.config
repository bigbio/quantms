/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/quantms Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // Workflow flags
    input              = null // the sdrf and spectra parameters are inferred from this one
    root_folder        = null
    local_input_type   = null
    database           = null
    acquisition_method = null

    // Tools flags
    posterior_probabilities  = 'percolator'
    add_decoys               = false
    enable_pmultiqc          = true
    search_engines           = 'comet'
    psm_pep_fdr_cutoff       = 0.10
    protein_level_fdr_cutoff = 0.05

    // Debug level
    decoydatabase_debug     = 0
    pp_debug                = 0
    idfilter_debug          = 0
    idscoreswitcher_debug   = 0
    iso_debug               = 0
    db_debug                = 0
    idpep_debug             = 0
    percolator_debug        = 0
    consensusid_debug       = 0
    idmapper_debug          = 0
    luciphor_debug          = 0
    protein_inference_debug = 0
    plfq_debug              = 0

    // decoys
    decoy_string                        = 'DECOY_'
    decoy_string_position               = 'prefix'
    decoy_method                        = 'reverse'
    shuffle_max_attempts                = 30
    shuffle_sequence_identity_threshold = 0.5

    // peak picking if used
    openms_peakpicking    = false
    peakpicking_inmemory  = false
    peakpicking_ms_levels = null // means all/auto

    //Isobaric analyze
    labelling_type              = null
    reference_channel           = 126
    min_precursor_intensity     = 1.0
    reporter_mass_shift         = 0.002
    select_activation           = 'HCD'
    isotope_correction          = true
    iso_normalization           = false
    min_reporter_intensity      = 0.0
    min_precursor_purity        = 0.0
    precursor_isotope_deviation = 10.0

    // shared search engine parameters
    enzyme                        = 'Trypsin'
    num_enzyme_termini            = 'fully'
    allowed_missed_cleavages      = 2
    precursor_mass_tolerance      = 5
    precursor_mass_tolerance_unit = 'ppm'
    fixed_mods                    = 'Carbamidomethyl (C)'
    variable_mods                 = 'Oxidation (M)'
    enable_mod_localization       = false
    mod_localization              = 'Phospho (S),Phospho (T),Phospho (Y)'
    fragment_mass_tolerance       = 0.03
    fragment_mass_tolerance_unit  = 'Da'
    fragment_method               = 'HCD' //currently unused. hard to find a good logic to beat the defaults
    isotope_error_range           = '0,1'
    instrument                    = null //auto-determined from tolerances
    protocol                      = 'automatic'
    min_precursor_charge          = 2
    max_precursor_charge          = 4
    min_peptide_length            = 6
    max_peptide_length            = 40
    num_hits                      = 1
    max_mods                      = 3

    // PeptideIndexer flags
    IL_equivalent    = true
    unmatched_action = "warn"

    // IDPEP flags
    outlier_handling = "none"

    // Falsediscoveryrate
    protein = false

    // Percolator flags
    train_FDR                    = 0.05
    test_FDR                     = 0.05
    FDR_level                    = 'peptide-level-fdrs'
    klammer                      = false
    description_correct_features = 0
    subset_max_train             = 300000

    // ConsensusID
    consensusid_algorithm           = 'best'
    min_consensus_support           = 0
    consensusid_considered_top_hits = 0

    // Luciphor options
    luciphor_neutral_losses       = null
    luciphor_decoy_mass           = null
    luciphor_decoy_neutral_losses = null

    // Epifany
    top_PSMs                 = 1
    update_PSM_probabilities = false

    // Protein inference
    picked_fdr               = true
    protein_score            = 'best' // Other options are "Best", "Product", "Sum"
    min_peptides_per_protein = 1
    use_shared_peptides      = true

    // ProteinQuantifier
    top                      = 3
    average                  = 'median'
    best_charge_and_fraction = false
    normalize                = false
    ratios                   = false
    fix_peptides             = false
    include_all              = true

    // ProteomicsLFQ flags
    protein_inference_method = 'aggregation'
    protein_quant            = 'unique_peptides'
    quantification_method    = 'feature_intensity'
    targeted_only            = true
    mass_recalibration       = false
    transfer_ids             = 'false'
    alignment_order          = 'star'
    add_triqler_output       = false
    quantify_decoys          = false

    // DIA-NN
    matrix_spec_q   = 0.01
    diann_debug     = 3
    // TODO think about unifying it with DDA parameters
    min_pr_mz       = null
    max_pr_mz       = null
    min_fr_mz       = null
    max_fr_mz       = null
    diann_normalize = true

    // MSstats
    skip_post_msstats = false
    ref_condition     = null
    contrasts         = 'pairwise'

    // PTXQC
    enable_qc           = false
    ptxqc_report_layout = null

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    max_multiqc_email_size     = '25.MB'

    // Boilerplate options
    outdir                     = null
    publish_dir_mode           = 'copy'
    tracedir                   = "${params.outdir}/pipeline_info"
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'modules'
    enable_conda               = false
    singularity_pull_docker_container = false

    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    hostnames                  = [:]
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    ebicluster{
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        conda.createTimeout = '1 h'
        conda.useMamba = true
        process.executor = 'lsf'
    }
    conda {
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        conda.useMamba    = true
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    test            { includeConfig 'conf/test.config'      }
    test_localize   { includeConfig 'conf/test_localize.config'}
    test_full       { includeConfig 'conf/test_full.config' }
    test_lfq        { includeConfig 'conf/test_lfq.config' }
    test_dia        { includeConfig 'conf/test_dia.config' }
    mambaci         { includeConfig 'conf/mambaci.config' }
}

// Load module config after profile, so they can depend on overwritten input parameters specific for each profile.
// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

manifest {
    name            = 'nf-core/quantms'
    author          = 'Yasset Perez-Riverol'
    homePage        = 'https://github.com/nf-core/quantms'
    description     = 'Quantitative Mass Spectrometry nf-core workflow'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
    version = '1.0'
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
